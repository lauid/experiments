{
  "apiVersion": "example.com/v1",
  "kind": "GPU",
  "metadata": {
    "name": "a100-01",
    "namespace": "default",
    "labels": {
      "gpu-type": "datacenter",
      "manufacturer": "nvidia"
    }
  },
  "spec": {
    "model": "A100",
    "memory": {
      "total": "80GB",
      "available": "75GB"
    },
    "computeCapability": "8.0",
    "architecture": "Ampere",
    "powerLimit": {
      "max": 400,
      "current": 300
    },
    "temperature": {
      "current": 55,
      "max": 85
    },
    "utilization": {
      "gpu": 25,
      "memory": 35
    },
    "status": "available",
    "nodeName": "gpu-cluster-01",
    "driverVersion": "535.86.10",
    "cudaVersion": "12.2",
    "processes": [
      {
        "pid": 23456,
        "name": "deep-learning-training",
        "memoryUsed": "5GB",
        "gpuUtilization": 25
      }
    ]
  },
  "status": {
    "phase": "Running",
    "conditions": [
      {
        "type": "Ready",
        "status": "True",
        "lastTransitionTime": "2024-01-15T10:30:00Z",
        "reason": "GPUAvailable",
        "message": "GPU is ready for use"
      }
    ],
    "lastUpdated": "2024-01-15T10:30:00Z"
  }
} 