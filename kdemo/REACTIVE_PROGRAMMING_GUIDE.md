# å“åº”å¼ç¼–ç¨‹è¯¦è§£æŒ‡å—

## ğŸš€ ä»€ä¹ˆæ˜¯å“åº”å¼ç¼–ç¨‹ï¼Ÿ

å“åº”å¼ç¼–ç¨‹æ˜¯ä¸€ç§**åŸºäºæ•°æ®æµå’Œå˜åŒ–ä¼ æ’­**çš„ç¼–ç¨‹èŒƒå¼ï¼Œå®ƒä½¿å¼€å‘è€…èƒ½å¤Ÿä»¥**å£°æ˜å¼**çš„æ–¹å¼æ„å»ºå¼‚æ­¥ã€éé˜»å¡çš„åº”ç”¨ç¨‹åºã€‚

### æ ¸å¿ƒç‰¹å¾
- **å¼‚æ­¥éé˜»å¡**ï¼šä¸ä¼šé˜»å¡çº¿ç¨‹ï¼Œæé«˜å¹¶å‘æ€§èƒ½
- **æ•°æ®æµé©±åŠ¨**ï¼šæ•°æ®ä»¥æµçš„å½¢å¼æµåŠ¨å’Œå¤„ç†
- **èƒŒå‹å¤„ç†**ï¼šä¼˜é›…å¤„ç†ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…é€Ÿåº¦ä¸åŒ¹é…
- **å£°æ˜å¼**ï¼šæè¿°"åšä»€ä¹ˆ"è€Œä¸æ˜¯"æ€ä¹ˆåš"
- **ç»„åˆæ€§**ï¼šæ“ä½œç¬¦å¯ä»¥ç»„åˆæˆå¤æ‚çš„æ•°æ®æµ

## ğŸ“Š ä¼ ç»Ÿç¼–ç¨‹ vs å“åº”å¼ç¼–ç¨‹å¯¹æ¯”

### ä¼ ç»ŸåŒæ­¥ç¼–ç¨‹
```java
// é˜»å¡å¼è°ƒç”¨ - æ¯ä¸ªæ“ä½œéƒ½ä¼šé˜»å¡çº¿ç¨‹
public List<Application> getApplications(String cluster, String namespace) {
    // é˜»å¡ç­‰å¾… Kubernetes API å“åº”
    List<Application> apps = kubernetesApi.list(namespace);
    
    // é˜»å¡å¤„ç†è¿‡æ»¤
    List<Application> filtered = apps.stream()
        .filter(app -> app.getStatus().getPhase().equals("Running"))
        .collect(Collectors.toList());
    
    // é˜»å¡å¤„ç†æ—¥å¿—
    for (Application app : filtered) {
        log.info("Found running app: {}", app.getName());
    }
    
    return filtered; // è¿”å›ç»“æœ
}
```

**é—®é¢˜ï¼š**
- æ¯ä¸ªæ“ä½œéƒ½é˜»å¡çº¿ç¨‹
- æ— æ³•å¤„ç†å¤§é‡å¹¶å‘è¯·æ±‚
- èµ„æºåˆ©ç”¨ç‡ä½
- éš¾ä»¥å¤„ç†è¶…æ—¶å’Œé”™è¯¯

### å“åº”å¼ç¼–ç¨‹
```java
// éé˜»å¡å¼è°ƒç”¨ - æ‰€æœ‰æ“ä½œéƒ½æ˜¯å¼‚æ­¥çš„
public Flux<Application> getApplications(String cluster, String namespace) {
    return kubernetesApi.list(namespace)
        .flatMapMany(Flux::fromIterable)  // è½¬æ¢ä¸ºæµ
        .filter(app -> "Running".equals(app.getStatus().getPhase()))  // è¿‡æ»¤
        .doOnNext(app -> log.info("Found running app: {}", app.getName()))  // å‰¯ä½œç”¨
        .onErrorResume(error -> {
            log.error("Error fetching applications: {}", error.getMessage());
            return Flux.empty();  // é”™è¯¯æ—¶è¿”å›ç©ºæµ
        })
        .timeout(Duration.ofSeconds(30));  // è¶…æ—¶æ§åˆ¶
}
```

**ä¼˜åŠ¿ï¼š**
- éé˜»å¡æ“ä½œï¼Œçº¿ç¨‹åˆ©ç”¨ç‡é«˜
- å¯ä»¥å¤„ç†å¤§é‡å¹¶å‘è¯·æ±‚
- å†…ç½®é”™è¯¯å¤„ç†å’Œè¶…æ—¶æ§åˆ¶
- æ“ä½œç¬¦å¯ä»¥ç»„åˆ

## ğŸ”§ Reactor æ¡†æ¶æ ¸å¿ƒæ¦‚å¿µ

### 1. Publisherï¼ˆå‘å¸ƒè€…ï¼‰
- **Mono<T>**ï¼šå‘å¸ƒ 0 æˆ– 1 ä¸ªå…ƒç´ 
- **Flux<T>**ï¼šå‘å¸ƒ 0 åˆ° N ä¸ªå…ƒç´ 

```java
// Mono ç¤ºä¾‹
Mono<String> singleResult = Mono.just("Hello World");
Mono<String> emptyResult = Mono.empty();
Mono<String> errorResult = Mono.error(new RuntimeException("Error"));

// Flux ç¤ºä¾‹
Flux<Integer> numbers = Flux.range(1, 10);
Flux<String> words = Flux.fromIterable(Arrays.asList("Hello", "World", "Reactive"));
```

### 2. æ“ä½œç¬¦ï¼ˆOperatorsï¼‰
æ“ä½œç¬¦ç”¨äºè½¬æ¢ã€è¿‡æ»¤ã€ç»„åˆæ•°æ®æµã€‚

#### è½¬æ¢æ“ä½œç¬¦
```java
Flux<Integer> numbers = Flux.range(1, 5);

// map - è½¬æ¢æ¯ä¸ªå…ƒç´ 
Flux<String> strings = numbers.map(n -> "Number: " + n);
// ç»“æœ: ["Number: 1", "Number: 2", "Number: 3", "Number: 4", "Number: 5"]

// flatMap - å¼‚æ­¥è½¬æ¢ï¼Œè¿”å›æ–°çš„ Publisher
Flux<String> asyncStrings = numbers.flatMap(n -> 
    Mono.just("Async Number: " + n).delayElement(Duration.ofMillis(100))
);
```

#### è¿‡æ»¤æ“ä½œç¬¦
```java
Flux<Integer> numbers = Flux.range(1, 10);

// filter - è¿‡æ»¤å…ƒç´ 
Flux<Integer> evenNumbers = numbers.filter(n -> n % 2 == 0);
// ç»“æœ: [2, 4, 6, 8, 10]

// take - å–å‰Nä¸ªå…ƒç´ 
Flux<Integer> firstThree = numbers.take(3);
// ç»“æœ: [1, 2, 3]

// skip - è·³è¿‡å‰Nä¸ªå…ƒç´ 
Flux<Integer> skipFirstThree = numbers.skip(3);
// ç»“æœ: [4, 5, 6, 7, 8, 9, 10]
```

#### ç»„åˆæ“ä½œç¬¦
```java
Flux<String> flux1 = Flux.just("A", "B", "C");
Flux<String> flux2 = Flux.just("1", "2", "3");

// concat - é¡ºåºè¿æ¥
Flux<String> concatenated = Flux.concat(flux1, flux2);
// ç»“æœ: ["A", "B", "C", "1", "2", "3"]

// merge - å¹¶è¡Œåˆå¹¶
Flux<String> merged = Flux.merge(flux1, flux2);
// ç»“æœ: ["A", "1", "B", "2", "C", "3"] (é¡ºåºä¸ç¡®å®š)

// zip - é…å¯¹ç»„åˆ
Flux<String> zipped = Flux.zip(flux1, flux2, (a, b) -> a + b);
// ç»“æœ: ["A1", "B2", "C3"]
```

## ğŸ—ï¸ é¡¹ç›®ä¸­çš„å“åº”å¼ç¼–ç¨‹åº”ç”¨

### 1. æ‰¹é‡æŸ¥è¯¢å®ç°åˆ†æ

è®©æˆ‘ä»¬è¯¦ç»†åˆ†æé¡¹ç›®ä¸­çš„æ‰¹é‡æŸ¥è¯¢å®ç°ï¼š

```java
@Override
public Mono<PrometheusBatchQueryResponse> batchQuery(String cluster, PrometheusQueryRequest request) {
    return Flux.fromIterable(request.getQueries())  // 1. å°†æŸ¥è¯¢åˆ—è¡¨è½¬æ¢ä¸ºæµ
        .flatMap(metricQuery -> executeSingleQuery(finalCluster, metricQuery, request)  // 2. å¹¶å‘æ‰§è¡Œæ¯ä¸ªæŸ¥è¯¢
            .map(result -> new PrometheusBatchQueryResponse.MetricResult(  // 3. è½¬æ¢ç»“æœ
                metricQuery.getName(),
                metricQuery.getDescription(),
                metricQuery.getQuery(),
                result,
                System.currentTimeMillis() - startTime
            ))
            .onErrorResume(throwable -> {  // 4. é”™è¯¯å¤„ç†
                logger.error("Query failed for metric {}: {}", metricQuery.getName(), throwable.getMessage());
                return Mono.empty();  // é”™è¯¯æ—¶è¿”å›ç©ºç»“æœ
            }), config.getMaxConcurrency())  // 5. æ§åˆ¶å¹¶å‘æ•°
        .collectList()  // 6. æ”¶é›†æ‰€æœ‰ç»“æœ
        .flatMap(results -> {  // 7. å¤„ç†ç»“æœ
            // æ„å»ºé”™è¯¯åˆ—è¡¨
            List<PrometheusBatchQueryResponse.QueryError> errors = new ArrayList<>();
            for (PrometheusQueryRequest.MetricQuery query : request.getQueries()) {
                boolean found = results.stream()
                    .anyMatch(result -> result.getName().equals(query.getName()));
                if (!found) {
                    errors.add(new PrometheusBatchQueryResponse.QueryError(
                        query.getName(),
                        query.getQuery(),
                        "Query execution failed",
                        "EXECUTION_ERROR"
                    ));
                }
            }
            // ç¡®å®šçŠ¶æ€
            String status = errors.isEmpty() ? "success" : "partial_success";
            if (results.isEmpty()) {
                status = "failed";
            }
            return Mono.just(new PrometheusBatchQueryResponse(status, results, errors));
        })
        .doOnSuccess(response -> {  // 8. æˆåŠŸå›è°ƒ
            logger.info("Batch query completed for cluster {}. Successful: {}, Failed: {}", 
                finalCluster, response.getSuccessfulQueries(), response.getFailedQueries());
        })
        .doOnError(throwable -> {  // 9. é”™è¯¯å›è°ƒ
            logger.error("Batch query failed for cluster {}: {}", finalCluster, throwable.getMessage());
        });
}
```

### 2. å…³é”®æ“ä½œç¬¦è§£æ

#### flatMap - å¹¶å‘å¤„ç†
```java
.flatMap(metricQuery -> executeSingleQuery(...), config.getMaxConcurrency())
```
- **ä½œç”¨**ï¼šå°†æ¯ä¸ªæŸ¥è¯¢è½¬æ¢ä¸ºå¼‚æ­¥æ“ä½œ
- **å¹¶å‘æ§åˆ¶**ï¼š`config.getMaxConcurrency()` é™åˆ¶åŒæ—¶æ‰§è¡Œçš„æŸ¥è¯¢æ•°é‡
- **ä¼˜åŠ¿**ï¼šé¿å…åˆ›å»ºè¿‡å¤šçº¿ç¨‹ï¼Œé˜²æ­¢èµ„æºè€—å°½

#### onErrorResume - é”™è¯¯æ¢å¤
```java
.onErrorResume(throwable -> {
    logger.error("Query failed for metric {}: {}", metricQuery.getName(), throwable.getMessage());
    return Mono.empty();  // è¿”å›ç©ºç»“æœè€Œä¸æ˜¯å¤±è´¥
})
```
- **ä½œç”¨**ï¼šå½“å•ä¸ªæŸ¥è¯¢å¤±è´¥æ—¶ï¼Œè¿”å›ç©ºç»“æœè€Œä¸æ˜¯æ•´ä¸ªæµå¤±è´¥
- **ä¼˜åŠ¿**ï¼šéƒ¨åˆ†å¤±è´¥ä¸å½±å“å…¶ä»–æŸ¥è¯¢çš„æ‰§è¡Œ

#### collectList - æ”¶é›†ç»“æœ
```java
.collectList()
```
- **ä½œç”¨**ï¼šå°† Flux è½¬æ¢ä¸º Mono<List<T>>
- **ç”¨é€”**ï¼šç­‰å¾…æ‰€æœ‰æŸ¥è¯¢å®Œæˆåç»Ÿä¸€å¤„ç†ç»“æœ

### 3. WebClient å“åº”å¼ HTTP å®¢æˆ·ç«¯

```java
private Mono<PrometheusQueryResponse> executeQuery(String cluster, String url, String queryType, String query) {
    return getWebClient(cluster).get()
        .uri(url)
        .retrieve()
        .bodyToMono(PrometheusQueryResponse.class)  // å“åº”å¼ååºåˆ—åŒ–
        .timeout(Duration.ofMillis(config.getTimeout()))  // è¶…æ—¶æ§åˆ¶
        .doOnSuccess(response -> logger.debug("Query successful"))  // æˆåŠŸå›è°ƒ
        .onErrorResume(WebClientResponseException.class, e -> {  // HTTPé”™è¯¯å¤„ç†
            logger.error("HTTP error: {} - {}", e.getStatusCode(), e.getResponseBodyAsString());
            return Mono.error(new PrometheusException("HTTP error: " + e.getStatusCode()));
        })
        .onErrorResume(throwable -> {  // å…¶ä»–é”™è¯¯å¤„ç†
            logger.error("Query failed: {}", throwable.getMessage());
            return Mono.error(new PrometheusException("Query execution failed"));
        });
}
```

## ğŸ¯ å“åº”å¼ç¼–ç¨‹çš„ä¼˜åŠ¿

### 1. æ€§èƒ½ä¼˜åŠ¿
```java
// ä¼ ç»Ÿæ–¹å¼ï¼šä¸²è¡Œå¤„ç†ï¼Œæ€»æ—¶é—´ = æŸ¥è¯¢1æ—¶é—´ + æŸ¥è¯¢2æ—¶é—´ + ... + æŸ¥è¯¢Næ—¶é—´
List<Result> results = new ArrayList<>();
for (Query query : queries) {
    Result result = executeQuery(query);  // é˜»å¡ç­‰å¾…
    results.add(result);
}

// å“åº”å¼æ–¹å¼ï¼šå¹¶è¡Œå¤„ç†ï¼Œæ€»æ—¶é—´ â‰ˆ max(æŸ¥è¯¢1æ—¶é—´, æŸ¥è¯¢2æ—¶é—´, ..., æŸ¥è¯¢Næ—¶é—´)
Flux.fromIterable(queries)
    .flatMap(this::executeQuery, maxConcurrency)  // å¹¶å‘æ‰§è¡Œ
    .collectList()
    .subscribe(results -> {
        // å¤„ç†ç»“æœ
    });
```

### 2. èµ„æºåˆ©ç”¨ç‡
```java
// ä¼ ç»Ÿæ–¹å¼ï¼šæ¯ä¸ªè¯·æ±‚ä¸€ä¸ªçº¿ç¨‹
@GetMapping("/applications")
public List<Application> getApplications() {
    // è¿™ä¸ªçº¿ç¨‹è¢«é˜»å¡ç›´åˆ°æ‰€æœ‰æ“ä½œå®Œæˆ
    return kubernetesService.getApplications();
}

// å“åº”å¼æ–¹å¼ï¼šå°‘é‡çº¿ç¨‹å¤„ç†å¤§é‡è¯·æ±‚
@GetMapping("/applications")
public Flux<Application> getApplications() {
    // çº¿ç¨‹ç«‹å³é‡Šæ”¾ï¼Œå¯ä»¥å¤„ç†å…¶ä»–è¯·æ±‚
    return kubernetesService.getApplications();
}
```

### 3. é”™è¯¯å¤„ç†
```java
// ä¼ ç»Ÿæ–¹å¼ï¼šå¼‚å¸¸ä¼ æ’­
try {
    List<Result> results = executeQueries(queries);
    return results;
} catch (Exception e) {
    // æ•´ä¸ªæ“ä½œå¤±è´¥
    throw new RuntimeException("All queries failed", e);
}

// å“åº”å¼æ–¹å¼ï¼šä¼˜é›…é™çº§
Flux.fromIterable(queries)
    .flatMap(this::executeQuery)
    .onErrorResume(error -> {
        log.error("Query failed: {}", error.getMessage());
        return Mono.empty();  // å•ä¸ªå¤±è´¥ä¸å½±å“æ•´ä½“
    })
    .collectList()
    .map(results -> {
        if (results.isEmpty()) {
            return new BatchResponse("failed", results, errors);
        } else {
            return new BatchResponse("partial_success", results, errors);
        }
    });
```

## ğŸ”„ èƒŒå‹å¤„ç†ï¼ˆBackpressureï¼‰

èƒŒå‹æ˜¯å“åº”å¼ç¼–ç¨‹ä¸­çš„é‡è¦æ¦‚å¿µï¼Œå¤„ç†ç”Ÿäº§è€…å’Œæ¶ˆè´¹è€…é€Ÿåº¦ä¸åŒ¹é…çš„é—®é¢˜ã€‚

### èƒŒå‹ç­–ç•¥
```java
Flux.range(1, 1000000)
    .onBackpressureBuffer(1000)  // ç¼“å†²ç­–ç•¥ï¼šç¼“å­˜1000ä¸ªå…ƒç´ 
    .onBackpressureDrop()        // ä¸¢å¼ƒç­–ç•¥ï¼šä¸¢å¼ƒæ— æ³•å¤„ç†çš„å…ƒç´ 
    .onBackpressureLatest()      // æœ€æ–°ç­–ç•¥ï¼šåªä¿ç•™æœ€æ–°å…ƒç´ 
    .onBackpressureError()       // é”™è¯¯ç­–ç•¥ï¼šèƒŒå‹æ—¶æŠ›å‡ºé”™è¯¯
    .subscribe(
        item -> processItem(item),  // æ¶ˆè´¹è€…
        error -> handleError(error),
        () -> System.out.println("Completed")
    );
```

### é¡¹ç›®ä¸­çš„åº”ç”¨
```java
// åœ¨æ‰¹é‡æŸ¥è¯¢ä¸­æ§åˆ¶å¹¶å‘æ•°ï¼Œé¿å…èƒŒå‹
.flatMap(metricQuery -> executeSingleQuery(...), config.getMaxConcurrency())
```

## ğŸ§ª æµ‹è¯•å“åº”å¼ä»£ç 

### å•å…ƒæµ‹è¯•
```java
@Test
void testBatchQuery() {
    // Given
    PrometheusQueryRequest request = new PrometheusQueryRequest();
    request.setQueries(Arrays.asList(
        new MetricQuery("cpu", "up", "CPU usage", new HashMap<>()),
        new MetricQuery("memory", "go_goroutines", "Memory usage", new HashMap<>())
    ));
    
    // When
    StepVerifier.create(prometheusService.batchQuery("cluster-local", request))
        .expectNextMatches(response -> {
            return "success".equals(response.getStatus()) &&
                   response.getResults().size() == 2;
        })
        .verifyComplete();
}
```

### é›†æˆæµ‹è¯•
```java
@Test
void testBatchQueryWithRealPrometheus() {
    // Given
    PrometheusQueryRequest request = createTestRequest();
    
    // When & Then
    StepVerifier.create(prometheusService.batchQuery("cluster-local", request))
        .expectNextMatches(response -> {
            assertThat(response.getStatus()).isIn("success", "partial_success");
            assertThat(response.getResults()).isNotEmpty();
            return true;
        })
        .verifyComplete();
}
```

## ğŸš€ æœ€ä½³å®è·µ

### 1. é”™è¯¯å¤„ç†
```java
// å¥½çš„åšæ³•ï¼šç»†ç²’åº¦é”™è¯¯å¤„ç†
Flux.fromIterable(queries)
    .flatMap(query -> executeQuery(query)
        .onErrorResume(TimeoutException.class, e -> {
            log.warn("Query timeout: {}", query.getName());
            return Mono.empty();
        })
        .onErrorResume(HttpException.class, e -> {
            log.error("HTTP error for query {}: {}", query.getName(), e.getMessage());
            return Mono.error(e);
        })
    )
    .collectList();
```

### 2. èµ„æºç®¡ç†
```java
// å¥½çš„åšæ³•ï¼šä½¿ç”¨ try-with-resources æˆ– doFinally
Flux.fromIterable(queries)
    .flatMap(this::executeQuery)
    .doFinally(signalType -> {
        // æ¸…ç†èµ„æº
        cleanup();
    })
    .collectList();
```

### 3. ç›‘æ§å’ŒæŒ‡æ ‡
```java
// å¥½çš„åšæ³•ï¼šæ·»åŠ ç›‘æ§æŒ‡æ ‡
Flux.fromIterable(queries)
    .flatMap(query -> executeQuery(query)
        .doOnSubscribe(s -> {
            // è®°å½•å¼€å§‹æ—¶é—´
            queryStartTime.put(query.getName(), System.currentTimeMillis());
        })
        .doOnSuccess(result -> {
            // è®°å½•æˆåŠŸæŒ‡æ ‡
            long duration = System.currentTimeMillis() - queryStartTime.get(query.getName());
            meterRegistry.timer("prometheus.query.duration", "query", query.getName())
                .record(duration, TimeUnit.MILLISECONDS);
        })
        .doOnError(error -> {
            // è®°å½•é”™è¯¯æŒ‡æ ‡
            meterRegistry.counter("prometheus.query.errors", "query", query.getName()).increment();
        })
    );
```

## ğŸ“š æ€»ç»“

å“åº”å¼ç¼–ç¨‹é€šè¿‡ä»¥ä¸‹æ–¹å¼æå‡åº”ç”¨ç¨‹åºæ€§èƒ½ï¼š

1. **éé˜»å¡æ“ä½œ**ï¼šæé«˜çº¿ç¨‹åˆ©ç”¨ç‡
2. **å¹¶å‘å¤„ç†**ï¼šåŒæ—¶å¤„ç†å¤šä¸ªè¯·æ±‚
3. **ä¼˜é›…é”™è¯¯å¤„ç†**ï¼šéƒ¨åˆ†å¤±è´¥ä¸å½±å“æ•´ä½“
4. **èƒŒå‹æ§åˆ¶**ï¼šé˜²æ­¢èµ„æºè€—å°½
5. **å£°æ˜å¼ç¼–ç¨‹**ï¼šä»£ç æ›´æ¸…æ™°ã€æ›´æ˜“ç»´æŠ¤

åœ¨è¿™ä¸ªé¡¹ç›®ä¸­ï¼Œå“åº”å¼ç¼–ç¨‹ä¸»è¦ç”¨äºï¼š
- **æ‰¹é‡æŸ¥è¯¢**ï¼šå¹¶å‘æ‰§è¡Œå¤šä¸ª Prometheus æŸ¥è¯¢
- **HTTP å®¢æˆ·ç«¯**ï¼šéé˜»å¡çš„ WebClient è°ƒç”¨
- **é”™è¯¯å¤„ç†**ï¼šä¼˜é›…å¤„ç†éƒ¨åˆ†æŸ¥è¯¢å¤±è´¥
- **æ€§èƒ½ä¼˜åŒ–**ï¼šé€šè¿‡å¹¶å‘æé«˜æŸ¥è¯¢æ•ˆç‡

é€šè¿‡å“åº”å¼ç¼–ç¨‹ï¼Œé¡¹ç›®èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤§é‡å¹¶å‘è¯·æ±‚ï¼Œæä¾›æ›´å¥½çš„ç”¨æˆ·ä½“éªŒå’Œç³»ç»Ÿæ€§èƒ½ã€‚ 